---
title: "Trabalho 3 - Modelos Lineares Generalizados"
author: "Vítor Pereira"
header-includes:
   - \usepackage[brazil]{babel}
   - \usepackage{bm}
geometry: left=1.7cm, right=1.7cm, top=3.33cm, bottom=3.2cm
output:
  bookdown::pdf_document2:
editor_options:
  chunk_output_type: console
indent: true
toc: false
---

```{r setup,include=F}

options(digits=6)  #Arrendodamento
options(scipen=999)
ggplot2::theme_set(ggplot2::theme_minimal()) #Tema dos gráficos produzidos no ggplot2
knitr::opts_chunk$set(echo=F,message=F,warning=F,fig.pos = 'H',fig.align = 'center',fig.width=7.8, fig.height=4.85)
scale_fill_discrete = \(...) ggplot2::scale_fill_brewer(... , palette="Set2") #Fixa a scale do fill dos gráficos do ggplot2
library(tidyverse)
library(patchwork)
turbina = scan("turbina.dat", list(tipo=0, tempo=0))
turbina$tipo = factor(turbina$tipo)
turbina <- dplyr::bind_cols(tempo = turbina$tempo, tipo = turbina$tipo)
turbina %>% mutate(n = 1:length(tipo)) -> turbina
```

```{r functions}
d=function(df,v1,v2,px){
  df %>% 
    ggplot(aes({{v1}},{{v2}})) +
    geom_point(size=2.1,color="red")+
    ggrepel::geom_text_repel(aes(label=n),size=2.8,point.padding = 0.3)
}

graph<-function(df,l){
  df %>% 
    as_tibble() %>% 
      ggplot(aes(as.numeric(row.names(df  %>% as_tibble())),value))+
      geom_point(color = 'black')+
      geom_hline(yintercept=l, linetype="dashed", color = "red")+
      geom_hline(yintercept=-l, linetype="dashed", color = "red")+
      labs(x="Índice")
    
}

fit2df<-function(fit) {
  summary(fit) |>
    (\(x) x$coefficients)() |>
    data.frame() |>
    round(3) |>
    mutate(P.valor = ifelse(
      `Pr...t..` < 0.001,"<0.001*",
      ifelse(`Pr...t..` < 0.05, paste0(`Pr...t..`, '*', sep = ''), `Pr...t..`))) |>
    select(-`Pr...t..`,
      "Estimativa" = "Estimate",
      "Desvio padrão" = "Std..Error",
      "Estatística t" = "t.value"
    )
}

dffts<-function(fitn,fitg,lab1,lab2){
    n = length(fitn$fitted.values)
  dffits(fitn) %>% 
 graph(2*sqrt(fitn$rank / n))+
  labs(title={{lab1}},y="DFfits")+
    ggrepel::geom_text_repel(aes(label=turbina$n),size=2.8,point.padding = 0.3) +
  dffits(fitg) %>% 
 graph(2*sqrt(fitn$rank / n))+
  labs(title={{lab2}},y="DFfits")
}

resid<-function(residuon,residuog,lab1,lab2){
 residuon %>% 
  graph(3)+
  geom_hline(yintercept = 0, linetype="dotted", color = "red")+
  labs(title={{lab1}},y="Resíduo")+
  residuog %>% 
  graph(3)+
  geom_hline(yintercept = 0, linetype="dotted", color = "red")+
  labs(title={{lab2}},y="Resíduo") 
}
cook<-function(fitn,fitg,lab1,lab2){
  n = length(fitn$fitted.values)
  cooks.distance(fitn) %>% 
  graph(4/(n-fitn$rank ))+ ggrepel::geom_text_repel(aes(label=turbina$n),size=2.8,point.padding = 0.3) +
  labs(title={{lab1}},y="Distância de Cook")+
  cooks.distance(fitg) %>% 
  graph(4/(n-fitg$rank ))+
  labs(title={{lab2}},y="Distância de Cook")
}

dffts1<-function(fitn,lab1){
  n = length(fitn$fitted.values)
  dffits(fitn) %>% 
 graph(2*sqrt(fitn$rank / n))+
  labs(title={{lab1}},y="DFfits")
}

resid1<-function(residuon,lab1){
 residuon %>% 
  graph(3)+
  geom_hline(yintercept = 0, linetype="dotted", color = "red")+
  labs(title={{lab1}},y="Resíduo")
}
cook1<-function(fitn,lab1){
    n = length(fitn$fitted.values)
  cooks.distance(fitn) %>% 
  graph(4/(n-fitn$rank ))+
  labs(title={{lab1}},y="Distância de Cook")
  
}

alavanca1 <- function(fit){
  h_bar=fit$rank/length(fit$fitted.values)
  hatvalues(fit) %>%
  graph(3*h_bar)+
  labs(title="Alavancagem",y="Medida de Alavancagem")
}

alavanca <- function(fit,fit2,lab1,lab2){
  h_bar=fit$rank/length(fit$fitted.values)
  h_bar2=fit2$rank/length(fit2$fitted.values)
  hatvalues(fit) %>%
  graph(3*h_bar)+
  labs(title={{lab1}},y="Medida de Alavancagem") +
  hatvalues(fit2) %>%
  graph(3*h_bar2)+
  labs(title={{lab2}},y="Medida de Alavancagem")
    
}
```

# Modelando o banco de dados
Modelares o banco de dados de um experimento para avaliar o desempenho de cinco tipos de turbinas de alta velocidade, levando em consideração 10 motores dos 5 tipos avaliados, analisando o tempo (em unidades de milhões de ciclos) até a perda da velocidade.

## Utilizando a Distribuição Gamma
Começaremos com a Distribuição Gamma, que é utilizada para modelar valores de dados positivos que são assimétricos à direita e maiores que 0.

### Primeiro Ajuste
Então começaremos a análise da Distribuição Gamma, considerando todos os tipos variáveis dummies e analisaremos sua significância:
```{r}
glm(tempo ~ tipo, family = Gamma(link = "log"), data = turbina) %>%
  fit2df() %>%
    mypdf1::pdf1_tbl("Primeiro Ajuste - Gamma")
```
Notamos, que os tipos não são completamente significativos, assim realizaremos junções buscando que as variáveis dummies sejam significativas.

### Segundo Ajuste
Iremos aglutinar os grupos 3 e 4 em um só, visto que foram os grupos que obtiveram maior p-valor na tabela anterior, assim temos:
```{r}
turbina %>% 
  mutate(tipo = case_when(as.numeric(tipo) == 3 ~ 4, TRUE ~ as.numeric(tipo))) %>%
  mutate(tipo = factor(tipo)) %>%
  glm(tempo ~ tipo, family = Gamma(link = "log"), data = .) %>%
  fit2df() %>%
    mypdf1::pdf1_tbl("Segundo Ajuste - Gamma")
```
Percebe-se que ainda não obtivemos significância em todos os tipos.

### Terceiro Ajuste
Agora iremos juntar os tipos 3 e 4 com o tipo 1, logo obtêm-se:
```{r}
turbina %>% 
  mutate(tipo = case_when(as.numeric(tipo) == 3 ~ 4, as.numeric(tipo) == 4 ~ 1, TRUE ~ as.numeric(tipo))) %>% 
  mutate(tipo = case_when(as.numeric(tipo) == 4 ~ 1, TRUE ~ as.numeric(tipo)))  %>%
  mutate(tipo = factor(tipo)) %>%
  glm(tempo ~ tipo, family = Gamma(link = "log"), data = .) -> fit1 
fit1 %>%
  fit2df() %>%
    mypdf1::pdf1_tbl("Terceiro Ajuste - Gamma")
```
Desse modo conseguimos significância em todas as variáveis e ficamos com 3 grupos, sendo 1 aglomerados, os grupos são: Tipo 1, 3 e 4, Tipo 2 e Tipo 5.


## Utilizando a Distribuição Normal Inversa
Agora utilizaremos a Distribuição Normal Inversa (NI), que também é utilizada para modelar valores de dados positivos e maiores que 0, analisaremos ao mesmo tempo a NI com ligação canônica $\dfrac{1}{\mu^2}$ e com a ligação $\log$.

### Primeiro ajuste
Considerando todos os tipos variáveis dummies, a significância fica:
```{r}
glm(tempo ~ tipo, inverse.gaussian(link = "1/mu^2"), data = turbina) %>%
  fit2df() %>%
    mypdf1::pdf1_tbl("Primeiro Ajuste - NI - Canônica")
glm(tempo ~ tipo, inverse.gaussian(link = "log"), data = turbina) %>%
  fit2df() %>%
    mypdf1::pdf1_tbl("Primeiro Ajuste - NI - log")
```
Notamos, que os tipos não são completamente significativos, assim realizaremos agregações em ambos modelos, buscando que as variáveis dummies sejam significativas.

### Segundo Ajuste
Iremos unir os grupos 3 e 4 em um só, visto que foram os grupos que obtiveram maior p-valor na tabela anterior, assim temos:
```{r}
turbina %>% 
  mutate(tipo = case_when(as.numeric(tipo) == 3 ~ 4, TRUE ~ as.numeric(tipo))) %>%
  mutate(tipo = factor(tipo)) %>%
  glm(tempo ~ tipo, inverse.gaussian(link = "1/mu^2"), data = .) %>%
  fit2df() %>%
    mypdf1::pdf1_tbl("Segundo Ajuste - NI - Canônica")
turbina %>% 
  mutate(tipo = case_when(as.numeric(tipo) == 3 ~ 4, TRUE ~ as.numeric(tipo))) %>%
  mutate(tipo = factor(tipo)) %>%
  glm(tempo ~ tipo, inverse.gaussian(link = "log"), data = .) %>%
  fit2df() %>%
    mypdf1::pdf1_tbl("Segundo Ajuste - NI - log")
```
Nota-se que ainda não obtivemos significância em todos os tipos, em nenhuma das distribuições NI.

### Terceiro Ajuste
Agora iremos juntar os tipos 3 e 4 com o tipo 1, logo obtêm-se:
```{r}
turbina %>% 
  mutate(tipo = case_when(as.numeric(tipo) == 3 ~ 4, TRUE ~ as.numeric(tipo))) %>%
  mutate(tipo = case_when(as.numeric(tipo) == 4 ~ 1, TRUE ~ as.numeric(tipo))) %>%
  mutate(tipo = factor(tipo)) %>%
  glm(tempo ~ tipo, inverse.gaussian(link = "1/mu^2"), data = .) -> fit2
fit2 %>%  
fit2df() %>%
    mypdf1::pdf1_tbl("Terceiro Ajuste - NI - Canônica")
turbina %>% 
  mutate(tipo = case_when(as.numeric(tipo) == 3 ~ 4, TRUE ~ as.numeric(tipo))) %>%
  mutate(tipo = case_when(as.numeric(tipo) == 4 ~ 1, TRUE ~ as.numeric(tipo))) %>%
  mutate(tipo = factor(tipo)) %>%
  glm(tempo ~ tipo, inverse.gaussian(link = "log"), data = .) -> fit3
  fit3 %>%
  fit2df() %>%
    mypdf1::pdf1_tbl("Terceiro Ajuste - NI - log")
```
Desse modo conseguimos significância em todas as variáveis e ficamos com 3 grupos, sendo 1 aglomerados, os grupos são: Tipo 1, 3 e 4, Tipo 2 e Tipo 5, tanto na Normal Inversa com ligação canônica, quanto na com ligação $\log$.

# Análise de Influência
Nesta seção será realizada uma busca de observações atípicas no banco de dados, que assim possam estar influenciado a análise, também influenciado pelas junções de tipos realizados anteriomente, assim utilizaremos 5 análises para a verificação de pontos de influência: Análise de Resíduos Deviance, Envelope Simulado, Distância de Cook, Alavancagem e DFFits.

## Ajuste com a Gamma
Começaremos a análise de influência com a distribuição Gamma.

### Resíduos deviances vs indices

```{r}
residuo1 <- residuals(fit1,type="deviance")
resid1(residuo1, "Resíduos do Modelo Gamma")
```

Não observa-se algum resíduo fora dos limites especificados, indicando que não exista pontos de influência.

### Envelope Simulado

```{r, results = F, fig.show='hide'}
g1 <- hnp::hnp(fit1, resid.type="deviance", halfnormal = F)
G1 <- with(g1, data.frame(x, lower, upper, median, residuals))

```

```{r}
G1 %>%
ggplot(aes(x)) +
  geom_point(aes(y = residuals)) +
  geom_line(aes(y = lower)) +
  geom_line(aes(y = upper)) +
  geom_line(aes(y = median), linetype = "dashed")
```
Todos os pontos estão dentro das bandas simuladas, indicando que a distribuição é adequada.

### Distância de Cook

```{r}
cook1(fit1, "Distância do Modelo Gamma") +
    ggrepel::geom_text_repel(aes(label=turbina$n),size=2.8,point.padding = 0.3)
```
Nota-se que as observações 47 e 49 ficam fora dos limites estipulados, mas sem achatar o gráfico da distância de cook, indicam que são potenciais pontos de influência, assim iremos tomar a decisão sobre a sua remoção posteriomente.

### Alavancagem

```{r}
alavanca1(fit1)
```
Observamos basicamente duas retas para a medida de alavancagem, mas nenhum delas fora dos limites estipulados, então não indicando pontos de influência.

### DFFits

```{r}
dffts1(fit1, "DFFits do Modelo Gamma")+
    ggrepel::geom_text_repel(aes(label=turbina$n),size=2.8,point.padding = 0.3)
```
Observamos que os pontos 5, 47 e 49 ficam fora dos limites estipulados, assim são candidatos a pontos de influência.

### Conclusão

Não iremos retirar nenhum dos candidatos a pontos influentes, pois são baixas as evidências, já que em apenas duas medidas são considerados pontos influentes, também não há o embasamento teórico para a realização dessa operação e ao que aparenta mesmo nas medidas em que são considerados pontos influentes, não há um achatamento acentuado do gráfico, como é visto em outros casos de pontos influentes, assim não parecem causar grande distorção nas estimativas da modelagem.

\subsection{Ajuste com a Normal inversa com link $\dfrac{1}{\mu^2}$ e link $\log$} 


### Resíduos deviances vs indices
```{r}
residuo2 <- residuals(fit2,type="deviance")
residuo3 <- residuals(fit3,type="deviance")
resid(residuo2, residuo3, "Resíduos do Modelo Normal Inversa Canônico", "Resíduos do Modelo Normal Inversa log" )
```
Para ambos resíduos que se assemelham muito, podemos concluir que não há sugestão de pontos de influentes.

### Envelope Simulado

```{r, results = F, fig.show='hide'}
g2 <- hnp::hnp(fit2, resid.type="deviance", halfnormal = F)
G2 <- with(g2, data.frame(x, lower, upper, median, residuals))
g3 <- hnp::hnp(fit3, resid.type="deviance", halfnormal = F)
G3 <- with(g3, data.frame(x, lower, upper, median, residuals))

```

```{r}
G2 %>%
ggplot(aes(x)) +
  geom_point(aes(y = residuals)) +
  geom_line(aes(y = lower)) +
  geom_line(aes(y = upper)) +
  geom_line(aes(y = median), linetype = "dashed") + labs(title="Envelope Simulado NI Canônico") + 
  G3 %>%
ggplot(aes(x)) +
  geom_point(aes(y = residuals)) +
  geom_line(aes(y = lower)) +
  geom_line(aes(y = upper)) +
  geom_line(aes(y = median), linetype = "dashed") + labs(title="Envelope Simulado NI log")
```

Todos os pontos estão dentro das bandas simuladas, indicando que a distribuição é adequada, mas nota-se também que apenas o envelope simulado da Normal Inversa log possui um ponto no limite da banda simulada.



### Distância de Cook

```{r}
cook(fit2, fit3, "Distância do Modelo Normal Inversa Canônico", "Distância do Modelo Normal Inversa log") +
    ggrepel::geom_text_repel(aes(label=turbina$n),size=2.8,point.padding = 0.3)
```

Assim como para a distribuição Gamma, percebe-se que as observações 47 e 49 ficam fora dos limites estipulados, mas sem achatar o gráfico da distância de cook, indicam que são potenciais pontos de influência em ambos os modelos.


### Alavancagem


```{r}
alavanca(fit2, fit3, "Alavancagem do Modelo Normal Inversa Canônico", "Alavancagem do Modelo Normal Inversa log") 
```
Observamos basicamente duas retas nos dois modelos para a medida de alavancagem, mas nenhum delas fora dos limites estipulados, então não indicando pontos de influência.

### DFFits

```{r}
dffts(fit2, fit3, "DFFits do Modelo NI Canônico", "DFFits do Modelo NI Inversa log")+
    ggrepel::geom_text_repel(aes(label=turbina$n),size=2.8,point.padding = 0.3)
```
Ao contrário da distribuição Gamma que tinha o ponto 49 como possível ponto influente, nos dois modelos temos que os pontos 1,2, 5 e 47 ficam fora dos limites estipulados, assim são candidatos a pontos de influência.

### Conclusão

A Justificativa para a não exclusão dos candidatos a pontos influentes é a mesma da Distribuição Gamma, acrescentando o fato que mesmo entre as duas medidas que possuem pontos influentes, apenas a observação 47 se repete, com as outras observações alternando, assim não iremos retirar nenhuma observação na modelagem da Normal Inversa.

# Comparação dos Modelos

## Média Gamma

```{r}
Mu<-fit1 %>%
  fit2df() %>%
  .$Estimativa
M1<-exp(sum(Mu*c(1,0,0)))
M2<-exp(sum(Mu*c(1,1,0)))
M3<-exp(sum(Mu*c(1,0,1)))
`Variação à B0` = c(0,(c(M2,M3) - M1)/abs(M1)*100)
m1 <- data.frame(Tipos = c("1, 3 e 4", "2", "5"), Média = c(M1,M2,M3), `Variação à B0` = `Variação à B0`)
m1 %>% mypdf1::pdf1_tbl("Médias da Distribuição Gamma")
```

Percebemos que os Tipos possuem médias bem diferentes matematicamente.


## Média Normal inversa com ligação canônica

```{r}
Mu2<-fit2 %>%
  fit2df() %>%
  .$Estimativa
M21<-1/sqrt(sum(Mu2*c(1,0,0)))
M22<-1/sqrt(sum(Mu2*c(1,1,0)))
M23<-1/sqrt(sum(Mu2*c(1,0,1)))

`Variação à B0` = c(0,(c(M22,M23) - M21)/abs(M21)*100)
m2 <- data.frame(Tipos = c("1, 3 e 4", "2", "5"), Média = c(M21,M22,M23), `Variação à B0` = `Variação à B0`)
m2 %>% mypdf1::pdf1_tbl("Médias da Distribuição NI canônica")
```

Médias semelhantes ao da distribuição Gamma, porém o grupo dos Tipos 1,3 e 4 e o Tipo 2 diminuiram a média, assim o Tipo 5 aumentou, a variação teve pequena alteração.

## Média Normal inversa com ligação log

```{r}
Mu3<-fit3 %>%
  fit2df() %>%
  .$Estimativa
M31<-exp(sum(Mu3*c(1,0,0)))
M32<-exp(sum(Mu3*c(1,1,0)))
M33<-exp(sum(Mu3*c(1,0,1)))

`Variação à B0` = c(0,(c(M32,M33) - M31)/abs(M31)*100)
m3 <- data.frame(Tipos = c("1, 3 e 4", "2", "5"), Média = c(M31,M32,M33), `Variação à B0` = `Variação à B0`)
m3 %>% mypdf1::pdf1_tbl("Médias da Distribuição NI log")
```

Exatamente iguais aos valores da Distribuição Gamma.

## Medidas de seleção
```{r}
med_modelo <- data.frame(Distribuição = c("Gamma"), c(parsnip::glance(fit1) |> select(-c(logLik,df.null,df.residual,nobs))))
med_modelo[nrow(med_modelo) +1, ] <- c("Normal Inversa Canônica", parsnip::glance(fit2) |> select(-c(logLik,df.null,df.residual,nobs)))
med_modelo[nrow(med_modelo) +1, ] <- c("Normal Inversa log", parsnip::glance(fit3) |> select(-c(logLik,df.null,df.residual,nobs)))
med_modelo %>%
mypdf1::pdf1_tbl("Medidas de Seleção de Modelo")
```
Assim, verificamos que com os modelos ajustados, temos que o melhor modelo para ser utilizado é o que contém a Distribuição Gamma, pois possuem menores valores no critério de AIC e BIC, assim perdendo mais informação, mas sendo extremamente próximos.

# Conclusão

Caso tivessemos que escolher algum desses modelos para estudar os dados escolheríamos o modelo que possui a distribuição Gamma, por possuir menor AIC e BIC. Nota-se alguns pontos interessantes, as médias dos modelos Gamma e Normal Inversa com ligação log são iguais, mas diferem nos critérios de seleção e nos critérios de seleção temos que a Distribuição Normal Inversa são iguais independente da função de ligação escolhida, assim optaríamos pelo modelo que possui a função de ligação canônica, pois possui melhores propriedades, principalmente assintoticamente.

